{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Best Practices Demonstration\n",
    "\n",
    "This Jupyter Notebook, `Pandas_1.ipynb`, is designed to showcase some of the best practices in pandas. Throughout this notebook, we will explore various pandas techniques that aim is to provide a practical guide to writing clean, memory efficient, and maintainable Python code. \n",
    "\n",
    "Let's dive in and start exploring Pandas best practices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- use PyArrow\n",
    "- review the data types after loading the dataframe\n",
    "- get function docs in place if possible. \n",
    "- check memory usage\n",
    "- chain your transformations\n",
    "- split the transformations maps/dictionaries \n",
    "- use `.query()`\n",
    "- define your filtering condtions as variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* Python can be very slow when you don't use the right tools and data types specially when you handle datasets because in Python \"everything is an object\"\n",
    "\n",
    "* There are continuous efforts to increase the scalability and the speed of pandas operations: Like Modin, `modin.pandas` data tool that implements Pandas API  to speed up the data loading and `apply` function \n",
    "\n",
    "* PyArrow is supported now to speed up in memory operation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is PyArrow \n",
    "\n",
    "* python library provides a Python API for functionality provided by the Arrow C++ libraries\n",
    "\n",
    "###  What is Arrow C++\n",
    "\n",
    "* Apache Arrow is a development platform for in-memory analytics\n",
    "* Arrow contains columnar vector and table-like containers supporting flat or nested types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__, np.__version__, pa.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataframe methods used : \n",
    "- `memory_usage` : Returns the memory usage of each column in bytes \n",
    "- `info` :  Prints information about a DataFrame including the index dtype and columns, non-null values and memory usage.\n",
    "- `describe`: Generates descriptive statistics.\n",
    "- `select_dtypes` : Returns a subset of the DataFrameâ€™s columns based on the column dtypes.\n",
    "- `query`: Query the columns of a DataFrame with a boolean expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "* Pandas enables choosing an engine to parse the loaded data in the dataframe. The default engine is Numpy, but we can also use Pyarrow, which is faster and more memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will time our code and check the memory usage as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_np = pd.read_csv('data/GSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# using PyArrow\n",
    "df_ar = pd.read_csv('data/GSS.csv', dtype_backend='pyarrow', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "gss_np = pd.read_csv('data/GSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%memit\n",
    "# using PyArrow\n",
    "df_ar = pd.read_csv('data/GSS.csv', dtype_backend='pyarrow', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why PyArrow?\n",
    "\n",
    "- PyaArrow enables faster conversion of dataframes between packages like pandas and polars(build using Rust Arrow ) as blob \n",
    "\n",
    "- PyArrow native string types saves memory over default pandas one.\n",
    "\n",
    "- PyArrow doesn't cast columns with integers + missing values to float columns like Numpy.\n",
    "- PyArrow will become a required dependency with pandas 3.0 [docs](https://pandas.pydata.org/docs/whatsnew/v2.1.0.html#pyarrow-will-become-a-required-dependency-with-pandas-3-0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gss_np = pd.read_csv('data/GSS.csv', index_col=0)\n",
    "gss_np.memory_usage(deep=True).sum() # ~35 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_np.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get column by datatype use `select_dtypes` and pass parmeters for type: \n",
    "    - specific type like `int8`\n",
    "    - generic like `integer`\n",
    "    - or `np.number`\n",
    "- To get more details you can  check the docs using command `df.select_dtypes?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_np.select_dtypes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gss = pd.read_csv('data/GSS.csv', index_col=0, dtype_backend='pyarrow', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy has int data types \n",
    "# # if you need to get details and limits use iinfo : \n",
    "import numpy as np\n",
    "np.iinfo(np.int8), np.iinfo(np.int16), np.iinfo(np.int32), np.iinfo(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Practice\n",
    "\n",
    "- chaining \n",
    "it makes the code more readable as set of steps or a receipe with one line at a time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nlargest and nsmallest vs sort_values\n",
    "gss['AGE'].nlargest(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss['AGE'].nsmallest(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining does not work with inplace=True \n",
    "# inplace=True is not recommended because it can slow down the code\n",
    "(gss['AGE']\n",
    " .sort_values(ascending=False)\n",
    " .head(3)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "(gss\n",
    " .nlargest(3, 'AGE', keep='all') \n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "(gss\n",
    " .nsmallest(3, 'AGE', keep='all') \n",
    " )\n",
    "# keep='all' to show all rows with the same value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints on transformation : \n",
    "\n",
    "#### Int types\n",
    "\n",
    "- pandas using numpy will not throw intger overflow error instead the dataframe cell will have inaccurate negative values.\n",
    "\n",
    "`soon we will see that ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remeber this line \n",
    "# gss.select_dtypes(int).describ()\n",
    "\n",
    "# is equal to \n",
    "(\n",
    "    gss\n",
    "    .select_dtypes(int)\n",
    "    .describe()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining casting into pyarrow types\n",
    "type_map = {'YEAR': 'uint16[pyarrow]', 'ID': 'uint16[pyarrow]', 'OCC': 'uint16[pyarrow]' }\n",
    "(gss\n",
    " .astype(type_map)\n",
    " .select_dtypes(['uint16'])\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining\n",
    "# Error in casting year to uint8\n",
    "# use 'integer' so see all int-like columns\n",
    "type_map_2 = {'YEAR': 'uint16[pyarrow]', 'ID': 'uint16[pyarrow]', 'OCC': 'uint16[pyarrow]' }\n",
    "(gss\n",
    " .astype(type_map_2) \n",
    " .select_dtypes(['integer'])  \n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "# this contains inaccuracy in the data\n",
    "(gss\n",
    " .astype({'YEAR': 'int8'})\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyarrow\n",
    "(gss\n",
    " .astype({'YEAR': 'int8[pyarrow]'})\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gss_np\n",
    ".select_dtypes('float')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast HRS1 to pyarrow int\n",
    "casting_types = {'HRS1': 'int8[pyarrow]','AGE': 'int8[pyarrow]'}\n",
    "(gss\n",
    " .astype(casting_types)\n",
    " .select_dtypes('integer')\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casting_types = {'HRS1': 'int8[pyarrow]','AGE': 'int8[pyarrow]'}\n",
    "(gss\n",
    " .astype(casting_types)\n",
    " .memory_usage(deep=True)\n",
    " .sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding values and NAs\n",
    "\n",
    "query(`string`) is more readable and easier for chaining . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gss\n",
    "  .query('AGE < 20')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are the missing values? \n",
    "# let's query\n",
    "\n",
    "(gss\n",
    "  .query('HRS1.isna()')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gss\n",
    "  .query('AGE.isna()')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the missing values using different method\n",
    "gss[gss['HRS1'].isna()]\n",
    "#gss[gss['AGE'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the using [] is prefered over query \n",
    "# you may use python best practice for the condition \n",
    "\n",
    "NA_HR_filter = gss['HRS1'].isna()\n",
    "\n",
    "gss[NA_HR_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for adding more than one condition \n",
    "NA_HR_filter = gss['HRS1'].isna()\n",
    "NA_AGE_filter = gss['AGE'].isna()\n",
    "\n",
    "NA_AGE_HRS_filter = NA_HR_filter & NA_AGE_filter\n",
    "\n",
    "gss[NA_AGE_HRS_filter]\n",
    "# should be equevalent to (gss\n",
    "#  .query('AGE.isna() and HRS1.isna()')\n",
    "#)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
