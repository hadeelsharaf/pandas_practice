{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Best Practices Demonstration\n",
    "\n",
    "This Jupyter Notebook, `Pandas_1.ipynb`, is designed to showcase some of the best practices in pandas. Throughout this notebook, we will explore various pandas techniques that aim is to provide a practical guide to writing clean, memory efficient, and maintainable Python code. \n",
    "\n",
    "Let's dive in and start exploring Pandas best practices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Python can be very slow when you don't use the right tools and data types specially when you handle datasets because in Python \"everything is an object\"\n",
    "\n",
    "* There are continuous efforts to increase the scalability and the speed of pandas operations: Like Modin, `modin.pandas` data tool that implements Pandas API  to speed up the data loading and `apply` function \n",
    "\n",
    "* PyArrow is introduced as an API to provide Arrow C++ functionality and interoperability with Pandas and Numpy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__, np.__version__, pa.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "* Pandas enables choosing an engine to parse the loaded data in the dataframe. The default engine is Numpy, but we can also use Pyarrow, which is faster and more memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will time our code and check the memory usage as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_np = pd.read_csv('data/GSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# using PyArrow\n",
    "df_ar = pd.read_csv('data/GSS.csv', dtype_backend='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Pyarrow?\n",
    "\n",
    "- PyaArrow enables faster conversion of dataframes between packages like pandas and  polars(build using Rust Arrow ) as blob \n",
    "\n",
    "- PyArrow native string types saves memory over default pandas one.\n",
    "\n",
    "- PyArrow doesn't cast columns with integers + missing values to float columns like Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gss_np = pd.read_csv('data/GSS.csv', index_col=0)\n",
    "gss_np.memory_usage(deep=True)#.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_np.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gss = pd.read_csv('data/GSS.csv', index_col=0, dtype_backend='pyarrow', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss.memory_usage(deep=True)#.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy has int data types if you need to get details and limit : \n",
    "import numpy as np\n",
    "np.iinfo(np.int8), np.iinfo(np.int16), np.iinfo(np.int32), np.iinfo(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Practice\n",
    "\n",
    "- chaning \n",
    "it makes the code more readable as set of steps or a receipe with one line at a time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints on transformation : \n",
    "\n",
    "#### Int types\n",
    "\n",
    "- pandas will not throw intger overflow error instead the dataframe cell will have inaccurate negative values.\n",
    "\n",
    "`soon we will see that ` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line \n",
    "# gss.select_dtypes(int).describ()\n",
    "\n",
    "# is equal to \n",
    "(\n",
    "    gss\n",
    "    .select_dtypes(int)\n",
    "    .describ()\n",
    ")\n",
    "# chaining casting into pyarrow types\n",
    "type_map = {'YEAR': 'uint16[pyarrow]', 'ID': 'uint16[pyarrow]', 'OCC': 'uint16[pyarrow]' }\n",
    "(gss\n",
    " .astype(type_map)\n",
    " .select_dtypes(['uint16'])\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaining\n",
    "# use 'integer' so see all int-like columns\n",
    "type_map_2 = {'YEAR': 'uint8[pyarrow]', 'ID': 'uint16[pyarrow]', 'OCC': 'uint16[pyarrow]' }\n",
    "(gss\n",
    " .astype(type_map_2) \n",
    " .select_dtypes(['integer'])  \n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy\n",
    "(gss\n",
    " .astype({'YEAR': 'int8'})\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyarrow\n",
    "(gss\n",
    " .astype({'YEAR': 'int8[pyarrow]'})\n",
    " .describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gss_np\n",
    ".select_dtypes('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are the missing values? \n",
    "# let's query\n",
    "\n",
    "(gss\n",
    "  .query('HRS1.isna()')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gss\n",
    "  .query('AGE.isna()')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
